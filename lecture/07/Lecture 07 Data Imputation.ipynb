{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "* Review: How are data missing?\n",
    "* Determining how data are missing\n",
    "* Missing data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Understanding How Data are Absent\n",
    "    \n",
    "* Missing Completely at Random (MCAR)\n",
    "    \n",
    "* Missing at Random (MAR)\n",
    "    \n",
    "* Not Missing at Random (NMAR)\n",
    "\n",
    "Describe them to your neightbor as if they are not experienced working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review MCAR/MAR/NMAR\n",
    "\n",
    "* **MCAR**: Data is *Missing Completely at Random* if there is no relationship between the missingness of the data and any values, observed or missing.\n",
    "\n",
    "* **MAR**:  Data is *Missing at Random* if there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data. \n",
    "\n",
    "* **NMAR**: Data is *Not Missing at Random* if there is a relationship between the propensity of a value to be missing and its values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "For each of the following datasets, decide whether they are MCAR, MAR, NMAR:\n",
    "* Self-reported income in the census.\n",
    "* Measurements transmitted back from the Hubble Space Telescope.\n",
    "* The Tail Number of a plane in the delayed flights data. \n",
    "* SAT scores reported by an institution for College Ranking scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCAR definition:\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "**MCAR**: Data is *Missing Completely at Random* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ } | Y_{obs}, Y_{mis}, \\psi) = Pr({\\rm data\\ is\\ present\\ } |\\ \\psi)$$\n",
    "\n",
    "That is, adding information on the dataset doesn't change likelihood data is missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MAR definition\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "\n",
    "**MAR**: Data is *Missing at Random* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ } | Y_{obs}, Y_{mis}, \\psi) = Pr({\\rm data\\ is\\ present\\ } |\\ Y_{obs}, \\psi)$$\n",
    "\n",
    "That is, *MAR data is actually MCAR, conditional on $Y_{obs}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NMAR definitions using distributions\n",
    "\n",
    "Suppose we have:\n",
    "- a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- a parameter $\\psi$ independent of the dataset.\n",
    "\n",
    "\n",
    "**NMAR**: Data is *Not Missing at Random* if \n",
    "\n",
    "$$Pr({\\rm data\\ is\\ present\\ }| Y_{obs}, Y_{mis}, \\psi)$$\n",
    "\n",
    "does not simplify. That is, in $NMAR$ data, missingness is dependent on the missing value itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: NMAR\n",
    "* Cannot determine NMAR from the data alone; it depends on the unobserved.\n",
    "* Must be reasoned by the data generating process, or more data should be collected.\n",
    "* The strength of the dependence on $Y_{mis}$ influences the strength of MNAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "* Consider a dataset of survey data of people's self-reported weights.\n",
    "    - The data contain an identifier and weight; nothing else.\n",
    "* Is the data likely NMAR? Why?\n",
    "* What data might you collect to make it not NMAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: MAR\n",
    "\n",
    "* Data are MAR if missingness only depends on *obsvered* data.\n",
    "* Data is MAR if it's determined to not be NMAR (assumption on data generating process).\n",
    "* Adding further measurements may reduce the effect of NMAR.\n",
    "    - income in census is MNAR; less so when adding geography, education, race..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to assess the mechanism of missingness: MCAR\n",
    "\n",
    "Given the assumption of MAR, you can test if a data are MCAR.\n",
    "\n",
    "A column `c_test` is MCAR if its missingness $R$ is independent of the data.\n",
    "* For each column `c`, check that the missingness rates of `c_test` are the same across values of `c`.\n",
    "* That is, the distribution of `c` when `c_test.isull()` is 'the same' as the distribution of `c` when `c_test.notnull()`.\n",
    "* The phrase 'the same' needs to be made statistically precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking data are MCAR: heights data\n",
    "* Start with complete dataset of child/parent heights.\n",
    "* Blank out rows to create MCAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = pd.read_csv('galton.csv')\n",
    "\n",
    "heights['child'] = heights.childHeight\n",
    "heights = heights.drop(['family', 'midparentHeight', 'children', 'childNum', 'childHeight'], axis=1)\n",
    "heights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of heights\n",
    "pd.plotting.scatter_matrix(heights.drop('gender', axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing data\n",
    "\n",
    "heights_mcar = heights.copy()\n",
    "idx = heights_mcar.sample(frac=0.3).index\n",
    "heights_mcar.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verifying that child heights are MCAR in `heights_mcar`\n",
    "* Check the data look the 'same' when `height` is null vs not-null\n",
    "    - Is the empirical distribution of gender similar for null/not-null?\n",
    "    - Is the empirical distribution of heights similar for null/not-null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "(\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .groupby(['is_null', 'gender'])\n",
    "    .size()\n",
    "    .rename('cnt')\n",
    "    .reset_index()\n",
    "    .pivot('is_null', 'gender', 'cnt')\n",
    "    .apply(lambda x:x/x.sum(), axis=0)\n",
    ").T.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heights: counts\n",
    "(\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='hist', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heights: distributions\n",
    "(\n",
    "    heights_mcar\n",
    "    .assign(is_null=heights_mcar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='kde', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child heights data: MAR\n",
    "* MAR is an *assumption* from the data\n",
    "* Once MAR is assumed, can show data is *not* MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build MAR dataset\n",
    "\n",
    "heights_mar = heights.copy()\n",
    "for i, row in heights.iterrows():\n",
    "    rand = np.random.uniform()\n",
    "    if (row['father'] > 72) and rand < 0.5:\n",
    "        heights_mar.loc[i, 'child'] = np.NaN\n",
    "    elif (row['gender'] == 'female') and rand > 0.7:\n",
    "        heights_mar.loc[i, 'child'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different missingness rates -- not MCAR\n",
    "\n",
    "(\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .groupby(['is_null', 'gender'])\n",
    "    .size()\n",
    "    .rename('cnt')\n",
    "    .reset_index()\n",
    "    .pivot('gender', 'is_null', 'cnt')\n",
    "    .apply(lambda x:x/x.sum())\n",
    ").plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different missingness rates -- not MCAR\n",
    "# Why is the right side of the graph different?\n",
    "(\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .groupby('is_null')\n",
    "    .father\n",
    "    .plot(kind='kde', legend=True, title='father height by missingness of child height')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When are two distributions 'the same'?\n",
    "* Need a way to measure the 'distance' between distributions (i.e. a statistic)\n",
    "* Need a way to determine when a large distance is meaningful (i.e. inference)\n",
    "    - discussed later in the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring the difference between distributions\n",
    "\n",
    "* Total Variation Distance measures the distance between distributions:\n",
    "    - see https://www.inferentialthinking.com/chapters/11/2/Multiple_Categories\n",
    "* If the distribution of a variable when `c` is missing is 'far' from the distribution when `c` is present, then the column is likely *not* MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Total Variation Distance (TVD)\n",
    "\n",
    "* Given two distributions $X$ and $Y$, the *total variation distance* is the sum of the absolute difference between the terms of $X$ and the terms in $Y$:\n",
    "\n",
    "$${\\rm TVD} = \\sum_i \\frac{|x_i - y_i|}{2}$$\n",
    "\n",
    "* In code:\n",
    "\n",
    "```\n",
    "def total_variation_distance(distr_1, distr_2):\n",
    "    return np.sum(np.abs(distr_1 - distr_2)) / 2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the TVD between the empirical distributions of gender in null/not-null heights data?\n",
    "\n",
    "# note: same as calculation above!\n",
    "distributions = (\n",
    "    heights_mar\n",
    "    .assign(is_null=heights_mar.child.isnull())\n",
    "    .pivot_table(columns='is_null', index='gender', values='child', aggfunc='size')\n",
    "    .apply(lambda x:x/x.sum(), axis=0)\n",
    ")\n",
    "\n",
    "distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = distributions[True] - distributions[False]\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why the divide by 2?\n",
    "# is this value large? what's the context?\n",
    "np.sum(np.abs(diff))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What to do with missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What to do with missing data?\n",
    "\n",
    "* Given a dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "* $Y$ may appear quite different than $Y_{obs}$:\n",
    "    - The mean and percentile may be different.\n",
    "    - The variance may be different.\n",
    "    - Correlations between variables may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple ways of dealing with missing data\n",
    "\n",
    "If the data are ______, `.dropna()` doesn't significantly change the data. That is, it produces unbiased estimates of means and variances.\n",
    "\n",
    "* MCAR (missing completely at random)\n",
    "\n",
    "* MAR (missing at random)\n",
    "\n",
    "* NMAR (not missing at random)\n",
    "\n",
    "* None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ways of dealing with missing data: deletion\n",
    "\n",
    "Using *listwise deletion* (dropping observations) to remove missing values:\n",
    "* Only works with *MCAR* data. (rare)\n",
    "* Removes observations with non-null data in other fields. (bad)\n",
    "* Doesn't further bias the observed dataset.\n",
    "\n",
    "Explain to yourself why these are true! (Recall DSC 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ways of dealing with missing data: imputation\n",
    "\n",
    "Imputation is the act of filling in missing data with plausable values.\n",
    "\n",
    "* Should be quick and easy to do\n",
    "* Shouldn't \"change\" the dataset\n",
    "\n",
    "These are hard to satisfy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imputation\n",
    "\n",
    "* imputation with a single value: mean, median, mode\n",
    "* imputation from a single value, with a model: regression, kNN\n",
    "* imputation by drawing from a distribution\n",
    "\n",
    "Each has upsides and downsides; each works differently with different types of missingness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean imputation\n",
    "\n",
    "* Imputing a missing value with the mean:\n",
    "    - preserves the mean of the observed data\n",
    "    - decreases the variance\n",
    "    - biases the means across groups when not *MCAR*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean imputation in the `heights` data\n",
    "* Mean imputation of MCAR data\n",
    "    - unbiased estimator of the mean.\n",
    "    - decreases variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of child heights\n",
    "plt.hist([heights_mcar.child.dropna(), heights.child])\n",
    "plt.legend(['missing (mcar)', 'full data']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with mean\n",
    "heights_mcar_mfilled = heights_mcar.fillna(heights_mcar.child.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'mean (original): %f' % heights.child.mean(),\n",
    "    'mean (missing):  %f' % heights_mcar.child.mean(),\n",
    "    'mean (mean imp): %f' % heights_mcar_mfilled.child.mean(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this smaller, given formula for std\n",
    "print(\n",
    "    'std (original): %f' % heights.child.std(),\n",
    "    'std (missing):  %f' % heights_mcar.child.std(),\n",
    "    'std (mean imp): %f' % heights_mcar_mfilled.child.std(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of child heights\n",
    "plt.hist([heights.child, heights_mcar.child.dropna(), heights_mcar_mfilled.child])\n",
    "plt.legend([ 'full data', 'missing (mcar)', 'imputed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean imputation and MAR data\n",
    "\n",
    "* Mean imputation leads to biased estimates of mean across groups, when using MAR data.\n",
    "* Since MAR is MCAR within each group, can do group-wise mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar1 = heights.copy()\n",
    "\n",
    "# blank out data for males at higher rate\n",
    "weights = heights_mar1.gender.replace({'male': 0.95, 'female': 0.05})\n",
    "idx = heights_mar1.sample(frac=0.3, weights=weights).index\n",
    "heights_mar1.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The observed vs true distribution\n",
    "plt.hist([heights.child, heights_mar1.child]);\n",
    "plt.legend([ 'full data','missing (mar)']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive mean imputation\n",
    "heights_mar1_mfilled = heights_mar1.fillna(heights_mar1.child.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'mean (original): %f' % heights.child.mean(),\n",
    "    'mean (missing):  %f' % heights_mar1.child.mean(),\n",
    "    'mean (mean imp): %f' % heights_mar1_mfilled.child.mean(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'std (original): %f' % heights.child.std(),\n",
    "    'std (missing):  %f' % heights_mar1.child.std(),\n",
    "    'std (mean imp): %f' % heights_mar1_mfilled.child.std(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([heights.child, heights_mar1.child, heights_mar1_mfilled.child]);\n",
    "plt.legend([ 'full data','missing (mar)', 'imputed']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biased mean by groups!\n",
    "# How is this connected to simpson's paradox?\n",
    "pd.concat([\n",
    "    heights.groupby('gender').child.mean().rename('full'),\n",
    "    heights_mar1.groupby('gender').child.mean().rename('missing (mar)'),\n",
    "    heights_mar1_mfilled.groupby('gender').child.mean().rename('imputed')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute separately by gender!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions: imputation with single values\n",
    "* Imputing missing data in a column with the mean of the column:\n",
    "    - faithfully reproduces the mean of the observed dataset,\n",
    "    - reduces the variance,\n",
    "    - biases relationships of the column with other columns.\n",
    "    \n",
    "* Similar with other statistics (median, mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "* Consider the income reporting in the US Census. \n",
    "* Suppose we impute missing salaries with the mean overall income.\n",
    "* Is there more bias in:\n",
    "    - (low-paying) service jobs or \n",
    "    - (high-paying) executive jobs?\n",
    "    \n",
    "Hint: what does the distribution of incomes look like? Where is the mean/median?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imputing missing values using distributions\n",
    "* We can *probalistically* impute missing data from a distribution.\n",
    "    - Fill in missing data by drawing from the distribution of *non-missing* data.\n",
    "* Recall: using `.sample`, we can draw from an (empirical) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imputing `heights_mcar` data by drawing from a distribution.\n",
    "\n",
    "Steps:\n",
    "* Sample values of child heights from the observed heights.\n",
    "* Fill in missing child heights by using these draws from the observed heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_null = heights_mcar.child.isnull().sum() # number of nulls\n",
    "fill_values = heights_mcar.child.dropna().sample(num_null, replace=True)  # draw fill vals from distribution\n",
    "fill_values.index = heights_mcar.loc[heights_mcar.child.isnull()].index  # align the index\n",
    "heights_mcar_dfilled = heights_mcar.fillna({'child': fill_values.to_dict()})  # fill the vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'mean (original):  %f' % heights.child.mean(),\n",
    "    'mean (missing):   %f' % heights_mcar.child.mean(),\n",
    "    'mean (distr imp): %f' % heights_mcar_dfilled.child.mean(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'std (original):  %f' % heights.child.std(),\n",
    "    'std (missing):   %f' % heights_mcar.child.std(),\n",
    "    'std (distr imp): %f' % heights_mcar_dfilled.child.std(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([heights.child, heights_mcar.child, heights_mcar_dfilled.child], density=True);\n",
    "plt.legend([ 'full data','missing (mcar)', 'distr imputed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observations\n",
    "* We only drew missing values from observed values. What if a missing value was previously unobserved?\n",
    "    - better to bin the data and draw from bins instead! \n",
    "    - use `np.histogram` to bin data.\n",
    "\n",
    "* How does this generalize to categoricals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observations\n",
    "\n",
    "* We created an imputed dataset using randomness to preserve variance\n",
    "* Our imputation could have been different, had we run it again\n",
    "* *Multiple imputation*: generate multiple imputed datasets and aggregate each result!\n",
    "    - Should remind you of bootstrap estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Imputation\n",
    "(Donald Rubin)\n",
    "\n",
    "Multiple imputation is a 3 step process:\n",
    "\n",
    "* **Imputation**: Impute a missing data multiple times (m times)\n",
    "* **Analysis**: Analyze each complete dataset separetly (m sets)\n",
    "* **Pooling**: Combine multiple analysis result. M estimates result in the final estimate.\n",
    "\n",
    "![](./imgs/mult_imp.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple Imputation: steps\n",
    "\n",
    "0. Start with observed and incomplete data. \n",
    "1. Create several **imputed** versions of the data by drawing from a distribution of plausible values.\n",
    "    - The imputed datasets are identical for the observed data entries, \n",
    "    - they differ in the imputed values. \n",
    "    - The differences reflect our **uncertainty** about what value to impute.\n",
    "\n",
    "2. Then we estimate the parameters of interest from **each** imputed dataset.\n",
    "3. The last step is to pool the m parameter estimates into one estimate and to estimate its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heights_mcar is our incomplete data\n",
    "\n",
    "def create_imputed(col):\n",
    "    num_null = col.isnull().sum()\n",
    "    fill_values = col.dropna().sample(num_null, replace=True)\n",
    "    fill_values.index = col.loc[col.isnull()].index\n",
    "    return col.fillna(fill_values.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_imputed(heights_mcar.child).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_imp = pd.concat([create_imputed(heights_mcar.child).rename(k) for k in range(100)], axis=1)\n",
    "mult_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 15 random imputations\n",
    "mult_imp.sample(15, axis=1).plot(kind='kde', alpha=0.5, legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling distribution of imputed means\n",
    "mult_imp.mean().plot(kind='hist', bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't decrease the standard deviations of imputed data\n",
    "mult_imp.std().plot(kind='hist', bins=50)\n",
    "std_incomplete = heights_mcar.child.std()\n",
    "plt.plot([std_incomplete, std_incomplete], [0,8]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "* Suppose we *average* all the multiple imputed heights and impute data using that average.\n",
    "* Does the variance of the imputed data:\n",
    "    - Remain the same?\n",
    "    - Decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = mult_imp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'std (original):  %f' % heights.child.std(),\n",
    "    'std (missing):   %f' % heights_mcar.child.std(),\n",
    "    'std (distr imp): %f' % imputed.std(),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([heights.child, heights_mcar.child, imputed], density=True);\n",
    "plt.legend([ 'full data','missing (mcar)', 'distr imputed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missingness, conditional on multiple variables\n",
    "* Use multiple imputation\n",
    "* Imputate from a distribution for each variable\n",
    "* Aggregate the multiple imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
