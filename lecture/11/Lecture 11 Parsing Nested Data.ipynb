{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import bs4\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parsing Nested Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Last time: scraping web data\n",
    "\n",
    "* GET requests result in HTML; What does this look like?\n",
    "* Let's see what is on the UCSD Data Science Events page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://dsc.ucsd.edu/node/10\"\n",
    "\n",
    "r = requests.get(url)\n",
    "    \n",
    "urlText = r.text\n",
    "\n",
    "Nchars = 10000\n",
    "print(urlText[:Nchars]) # Print the first 500 characters\n",
    "print(\"\\n\\n... \" + str(len(urlText)-Nchars) + \" additional characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extracting information from HTML\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* If you want to scrape tabular data:\n",
    "    - it's as easy as `pd.read_html`\n",
    "\n",
    "* Scraping `basketball-reference.com` tables:\n",
    "\n",
    "<img src=\"imgs/nba.png\" width=\"50%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = pd.read_html('https://www.basketball-reference.com/leagues/NBA_2017_per_game.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extracting information from HTML\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* If your data is *not* tabular:\n",
    "    - need to parse the HTML\n",
    "    - determine what to extract\n",
    "    - transform HTML to a tabular structure\n",
    "    \n",
    "* The data may lies on multiple pages.\n",
    "\n",
    "<img src=\"imgs/dsc.png\" width=\"50%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nchars = 10000\n",
    "print(urlText[:Nchars]) # Print the first 500 characters\n",
    "print(\"\\n\\n... \" + str(len(urlText)-Nchars) + \" additional characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is HTML?\n",
    "\n",
    "* HTML (HyperText Markup Language) is the most basic building block of the Web. \n",
    "* It defines the content and layout of a web-page.\n",
    "\n",
    "* HTML markup includes special \"elements\" (tags) such as \n",
    "    * `<head>, <title>, <body>, <p>, <div>, <img>`,.....\n",
    "    \n",
    "\n",
    "See [this tutorial](http://fab.academany.org/2018/labs/fablaboshanghai/students/bob-wu/Fabclass/week2_project_management/HTML.html) for more reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an HTML page, inline\n",
    "HTML(open('data/lec10.html').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Anatomy of HTML\n",
    "\n",
    "* **HTML Document**: the totality of markup that makes up a web-page\n",
    "* **Document Object Model**: the internal representation of a HTML document as a *tree* structure.\n",
    "\n",
    "* **HTML Element**: An object in the DOM, such as a paragraph, header, title.\n",
    "* **HTML Tags**: Markers that denote the *start* and *end* of an element. E.g. `<p>` and `</p>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec10.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HTML Tags\n",
    "\n",
    "HTML tags define both:\n",
    "* document structure elements and \n",
    "* document head/body elements.\n",
    "\n",
    "<img src=\"imgs/webpage_anatomy.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful tags to know:\n",
    "\n",
    "|Structure Elements|Description|Head/Body Elements|Description|\n",
    "|---|---|---|---|\n",
    "|`<html>`|the document|`<p>`|the paragraph|\n",
    "|`<head>`|the header|`<h1>, <h2>, ...`|header(s)|\n",
    "|`<body>`|the body|`<img>`|images|\n",
    "|`<div>` |a logical division of the document|`<a>`| anchor (hyper-link)|\n",
    "|`<span>`|an *in-line* logical division|[MANY MORE](https://en.wikipedia.org/wiki/HTML_element)||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Images and Hyperlinks\n",
    "\n",
    "* Tag for a picture (can use a link to the image):\n",
    "```\n",
    "<img src=\"HumDum.png\" alt=\"Humbpty Dumpty\">\n",
    "```\n",
    "\n",
    "* Tag for a hyperlink: \n",
    "\n",
    "```\n",
    "<a href=\"https://ucsd.edu/\">Visit our page!</a>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec10_pic_ref.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(open('data/lec10_pic_ref.html').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The HTML Document Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The HTML Document Tree\n",
    "\n",
    "* DOM represents a document as a logical tree.\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/webpage_anatomy.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"imgs/dom_tree.png\" width=\"50%\">\n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The tree structure *does* matter\n",
    "\n",
    "* HTML parsing methods return tree-like objects.\n",
    "* Tree algorithms used (e.g. BFS vs DFS) affect parsing performance.\n",
    "* \"Flattening\" trees to tables requires choices (and DIY techniques).\n",
    "* Manipulation of pages (e.g. with javascript) requires manipulating tree structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: \"quotes collection\" website\n",
    "\n",
    "* What do you think the DOM tree look like? (roughly)\n",
    "* What would your table schema (i.e. rows/columns) look like?\n",
    "\n",
    "<img src=\"imgs/quotes2scrape.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example (rough) document tree\n",
    "\n",
    "* How you would you parse it, if you wanted to collect data:\n",
    "    - Quote-by-quote (all attributes)?\n",
    "    - Attribute-by-attribute?\n",
    "    \n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/quotes2scrape.png\" width=\"50%\">\n",
    "    \n",
    "<img src=\"imgs/quote_dom.png\" width=\"50%\">\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BeautifulSoup: parsing the document tree\n",
    "\n",
    "* [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a python HTML parser.\n",
    "* **Warning:** BeautifulSoup has changed between versions, so make sure you are looking at documentation for the version you are using (4 here).\n",
    "\n",
    "* Parse a small HTML \"page\", with corresponding tree below:\n",
    "\n",
    "<img src=\"imgs/dom_tree_1.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''\n",
    "<body>\n",
    "\n",
    "  <div id=\"content\">\n",
    "    <h1>Heading here</h1>\n",
    "    <p>My First paragraph</p>\n",
    "    <p>My <em>second</em> paragraph</p>\n",
    "    <hr>\n",
    "  </div>\n",
    "  \n",
    "  <div id=\"nav\">\n",
    "    <ul>\n",
    "      <li>item 1</li>\n",
    "      <li>item 2</li>\n",
    "      <li>item 3</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BeautifulSoup Parsing\n",
    "\n",
    "* `bs4.BeautifulSoup` parses a string or file-like object representing HTML\n",
    "* Returns a *parsed document*\n",
    "* Use the `children` property to access child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(bs4.BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(s)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print just the text\n",
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children\n",
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = list(soup.children)[0]\n",
    "\n",
    "list(root.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "What is the output of the following code:\n",
    "```\n",
    "list(list(list(soup.children)[0].children)[0].children)[-2]\n",
    "```\n",
    "(*Note:* the output is a node element; if `-2` were `-1`, then the value would be `\\n`)\n",
    "\n",
    "\n",
    "<img src=\"imgs/dom_tree_1.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(list(soup.children)[0].children)[0].children)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(list(soup.children)[0].children)[0].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Document tree traversal: depth-first\n",
    "\n",
    "* Using `.children` attribute, traverse `soup` depth-first.\n",
    "* Take care to only print node elements!\n",
    "\n",
    "<img src=\"imgs/dom_tree_1.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Document tree traversal: depth-first\n",
    "\n",
    "* Using `.children` attribute, traverse `soup` depth-first.\n",
    "* Take care to only print node elements!\n",
    "\n",
    "<img src=\"imgs/dom_tree_1.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth first search\n",
    "\n",
    "def dfs(elt, visited):\n",
    "    if elt not in visited:\n",
    "        visited.append(elt)\n",
    "        print(elt.name)\n",
    "        for e in elt:\n",
    "            if not isinstance(e, str):\n",
    "                dfs(e, visited)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs(soup, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFS using `descendants` property\n",
    "children = []\n",
    "for x in soup.descendants:\n",
    "    children.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting attributes of nodes\n",
    "* The `.text` property of a tag element gets the text elements between the tags.\n",
    "* The `.attrs` property lists all attributes of a tag.\n",
    "* The `.get(key)` method, gets the value of a tag attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = list(soup.descendants)[5]\n",
    "hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = list(soup.descendants)[20]\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = list(soup.descendants)[20]\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting subtrees of the document tree\n",
    "\n",
    "* Use the BeautifulSoup methods `find_**` to select subtrees\n",
    "* `soup.find(name=None, attrs={}, recursive=True, text=None, **kwargs)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting subtrees of the document tree\n",
    "\n",
    "* Using `soup.find('div')`:\n",
    "\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "<img src=\"imgs/dom_tree_1.png\" width=\"50%\">\n",
    "  \n",
    "<img src=\"imgs/dom_subtree_1.png\" width=\"40%\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div')\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', attrs={'id': 'nav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: extracting data from HTML\n",
    "\n",
    "* Let's parse the `dsc.ucsd.edu` schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"http://dsc.ucsd.edu/node/10\"\n",
    "# r = requests.get(url)   \n",
    "# urlText = r.text\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(urlText, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can extract the title of the document\n",
    "\n",
    "soup.find('title')\n",
    "# soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('title').contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can extract the first paragraph \n",
    "\n",
    "soup.find('p')\n",
    "\n",
    "# open link in the browser, right click and \"page source\". Can you find <p> tags?\n",
    "# and hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the links\n",
    "\n",
    "all_links  = soup.find_all('a')\n",
    "all_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = all_links[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the links and their urls\n",
    "for link in soup.find_all('a'):\n",
    "    print('%s:%s(%s)' %(link.text, ' '*(50 - len(link.text)) , link.get('href', ' ')[:50]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the text as a string\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: scraping quotes\n",
    "* Collect famous quotes and related data\n",
    "* Requires scraping many pages to get data\n",
    "* Parse the pages to extract information\n",
    "\n",
    "<img src=\"imgs/quotes2scrape.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping quotes: steps\n",
    "1. What information to collect?\n",
    "2. What pages are needed to visit? In what order?\n",
    "3. What does our table schema look like?\n",
    "\n",
    "<img src=\"imgs/quotes2scrape.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping quotes:\n",
    "# Columns: quote, author, author bio, binary column for each tag\n",
    "# Create a dictionary (JSON) for each record\n",
    "# Translate dictionary => dataframe\n",
    "# make 1-2 observations about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping quotes: proposed plan\n",
    "\n",
    "1. Function `scrape_pages(urllist)` that scrapes a list of urls.\n",
    "    - `requests` is only used here!    \n",
    "2. Function `parse_quote_list(soup)` that selects the quotes information from a quote page.\n",
    "3. Function `parse_author_info(author_soup)` that selects the author information from an author page.\n",
    "\n",
    "**Tip:** Have functions that request and functions that parse, but not both! \n",
    "- Easier to debug and catch errors!\n",
    "- Avoids unnecessary requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposed plan:\n",
    "\n",
    "def scrape_pages(urllist):\n",
    "    \n",
    "    out = []\n",
    "    for url in urllist:\n",
    "        \n",
    "        # 1. request pages\n",
    "        # 2. parse page w/bs4\n",
    "        # 3. parse each quote on quote page\n",
    "        #         4. extract info from each quote\n",
    "        #         5. get author URL for each quote\n",
    "        #         6. request auth page / parse / extract\n",
    "        # 7. Add parsed info (DF) to out\n",
    "        pass\n",
    "        \n",
    "    return pd.concat(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping quotes: `parse_quote_list(soup)`\n",
    "* Develop function on a single page of quotes\n",
    "* Wrap code in `parse_quote_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('http://quotes.toscrape.com/page/%d/' % 1)\n",
    "soup = bs4.BeautifulSoup(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need: quote text, author name, author url, tags\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab each quote and parse!\n",
    "# A quote is defined by a div with class \"quote\"!\n",
    "quote = soup.find('div', attrs={'class': 'quote'})\n",
    "quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quote text\n",
    "quote_text = quote.find('span', attrs='text').text\n",
    "quote_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author name\n",
    "quote_auth = quote.find('small', attrs={'class': 'author'}).text\n",
    "quote_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author url\n",
    "auth_url = quote.find('a').get('href')\n",
    "auth_url = 'http://quotes.toscrape.com' + auth_url\n",
    "auth_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags\n",
    "quote.find('div', attrs={'class': 'tags'})\n",
    "\n",
    "#quote.find('div', attrs={'class': 'tags'}).find_all('a')\n",
    "\n",
    "#quote_tags = [x.text for x in quote.find('div', attrs={'class': 'tags'}).find_all('a')]\n",
    "#quote_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {}\n",
    "row['quote_text'] = quote_text\n",
    "row['quote_auth'] = quote_auth\n",
    "row['auth_url'] = auth_url\n",
    "for tag in quote_tags:\n",
    "    row[tag] = 1\n",
    "\n",
    "# Single row\n",
    "pd.Series(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quote_list(soup):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    # Loop through all quotes\n",
    "    quotes = soup.find_all('div', attrs={'class': 'quote'})\n",
    "    for quote in quotes:\n",
    "        \n",
    "        # parse quote elements\n",
    "        quote_text = quote.find('span', attrs='text').text\n",
    "        quote_auth = quote.find('small', attrs={'class': 'author'}).text\n",
    "        auth_url = quote.find('a').get('href')\n",
    "        quote_tags = [x.text for x in quote.find('div', attrs={'class': 'tags'}).find_all('a')]\n",
    "        \n",
    "        # column - value mapping\n",
    "        row = {}\n",
    "        row['quote_text'] = quote_text\n",
    "        row['quote_auth'] = quote_auth\n",
    "        row['auth_url'] = 'http://quotes.toscrape.com' + auth_url\n",
    "        for tag in quote_tags:\n",
    "            row['tag_%s' % tag] = 1\n",
    "\n",
    "        out.append(row)\n",
    "        \n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quotes_df = parse_quote_list(soup)\n",
    "quotes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping quotes: `parse_author_info(author_soup)`\n",
    "* Develop function on a single author page.\n",
    "* Wrap code in `parse_author_info(author_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = quotes_df.auth_url.iloc[0]\n",
    "author_resp = requests.get(url)\n",
    "author_soup = bs4.BeautifulSoup(author_resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# author bio, author bday, original url (to join)\n",
    "author_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dob = author_soup.find('span', attrs={'class': 'author-born-date'}).text\n",
    "bio = author_soup.find('div', attrs={'class': 'author-description'}).text\n",
    "author = author_soup.find('h3', attrs={'class': 'author-title'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_row = {'dob': dob, 'bio': bio, 'quote_auth': author}\n",
    "auth_row # how to clean bio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_author_info(author_soup):\n",
    "    '''returns extracted author information from a parsed author page'''\n",
    "    \n",
    "    dob = author_soup.find('span', attrs={'class': 'author-born-date'}).text\n",
    "    bio = author_soup.find('div', attrs={'class': 'author-description'}).text.strip()\n",
    "    author = author_soup.find('h3', attrs={'class': 'author-title'}).text.strip()\n",
    "    \n",
    "    return {'dob': dob, 'bio': bio, 'quote_auth': author}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_author_info(author_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping quotes: Putting it together\n",
    "\n",
    "* `scrape_pages` takes a list of urls and returns a dataframe of extracted info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposed plan:\n",
    "\n",
    "def scrape_pages(urllist):\n",
    "    \n",
    "    out = []\n",
    "    for url in urllist:\n",
    "        resp = requests.get(url)\n",
    "        soup = bs4.BeautifulSoup(resp.text)\n",
    "        if not resp.ok:\n",
    "            return\n",
    "        \n",
    "        # parse quotes (dataframe):\n",
    "        url_quotes = parse_quote_list(soup)\n",
    "        out.append(url_quotes)\n",
    "        \n",
    "    quote_df = pd.concat(out, sort=False)\n",
    "        \n",
    "    # get author urls (fewest requests possible!)\n",
    "    \n",
    "    auth_out = []\n",
    "    auth_urls = quote_df['auth_url'].unique()\n",
    "    for auth_url in auth_urls:\n",
    "        auth_resp = requests.get(auth_url)\n",
    "        auth_soup = bs4.BeautifulSoup(auth_resp.text)\n",
    "        auth = parse_author_info(auth_soup)\n",
    "        auth_out.append(auth)\n",
    "        \n",
    "    auth_df = pd.DataFrame(auth_out)\n",
    "    \n",
    "    out_df = quote_df.merge(auth_df, on='quote_auth', how='left')\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllist = ['http://quotes.toscrape.com/page/%d/' % x for x in range(1,3)]\n",
    "urllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrape_pages(urllist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quote_auth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping quotes: conclusion\n",
    "\n",
    "* Make as few requests as possible\n",
    "* Create a request/parsing plan *beforehand*\n",
    "* Create your output schema *beforehand*\n",
    "* Separate parsing and requests into different functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested vs flat data structures\n",
    "\n",
    "* Nested: HTML, JSON, XML\n",
    "* Flat: CSV\n",
    "\n",
    "Suppose we obtained the quotes data via an API and saved it to the file `quotes2scrape.json`\n",
    "- `quotes2scrape.json` is a 'json records file'; each line is a valid json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(open('data/quotes2scrape.json').readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the lines: each element is a dictionary\n",
    "L = [json.loads(x) for x in open('data/quotes2scrape.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What happended to the tags column?\n",
    "df = pd.DataFrame(L)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_tags = np.unique(df.tags.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2series(taglist):\n",
    "    return pd.Series({k:1 for k in taglist})\n",
    "\n",
    "tags = df.tags.apply(list2series)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine them\n",
    "pd.concat([df, tags], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Converting JSON to CSV\n",
    "\n",
    "* Flattening the nested list requires a lot of space. Why?\n",
    "* We can't always read in *all* the JSON; might need to extract just what we need line-by-line.\n",
    "* A JSON records file is **not** valid JSON. Why? Why can't we just use JSON?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
