{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling pipeline\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The steps of the modeling pipeline\n",
    "\n",
    "1. Create features to best reflect the meaning behind data\n",
    "2. Create model appropriate to capture relationships between features\n",
    "    - e.g. linear, non-linear\n",
    "3. Select a loss function and fit the model (determine $\\hat{\\theta}$).\n",
    "4. Evaluate model (e.g. using RMSE)\n",
    "\n",
    "After these steps, use the model for prediction and/or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Software development and the modeling pipeline \n",
    "\n",
    "* Each step may contain complicated transformations and logic\n",
    "* The pipeline above represents a single attempt at a model\n",
    "    - May have thousands of feature/model/paramater combinations to choose from!\n",
    "    - Remember the Data Science Life Cycle!\n",
    "* ML pipelines: [the high interest credit card of technical debt](https://ai.google/research/pubs/pub43146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features and Models using `Scikit Learn`\n",
    "\n",
    "* Scikit-Learn implements many common steps in the feature/model creation pipeline.\n",
    "* It interfaces with `numpy` arrays, *not* Pandas dataframes :(\n",
    "    - Some work required keeping track of columns in scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn feature transformers\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_1.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn (linear) models\n",
    "\n",
    "<img src=\"imgs/image_2.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Transformer Classes\n",
    "\n",
    "* Initialize a feature transformer with parameters:\n",
    "    - e.g. `binar = Binarizer(thresh)`\n",
    "* Transform data using `.transform` method\n",
    "    - e.g. `binar.transform(data)` creates binarized features from `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Binarizer(threshold=20)\n",
    "binarized = bi.transform(tips[['total_bill']])\n",
    "binarized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat([tips.total_bill, pd.DataFrame(binarized, columns=['binarized'])], axis=1)\n",
    "    .sort_values('total_bill')\n",
    "    .plot(x='total_bill', y='binarized')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Model Classes\n",
    "\n",
    "* Initialize a model with (perhaps zero) parameters:\n",
    "    - e.g. `lr = LinearRegression()`\n",
    "* Fit model to given dataset using `.fit`\n",
    "    - e.g. `lr.fit(data, outcomes)` fits the model weights using `data` and `outcomes`.\n",
    "* Use the model to predict using `.predict` method\n",
    "    - e.g. `lr.predict(newdata)` predicts outcomes for `newdata`.\n",
    "* Inspect model attributes, like model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(tips[['total_bill', 'size']], tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(tips[['total_bill', 'size']])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression coefficients\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it together: Scikit-Learn Pipelines\n",
    "\n",
    "* Put together feature transformers and models using `sklearn.Pipeline` objects\n",
    "* Create a pipeline: `pl = Pipeline([feat, mdl])`\n",
    "* Fit the model(s) in the pipeline using `pl.fit(data, target)`\n",
    "* Predict from *raw* input data through the pipeline using `pl.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('one-hot', DictVectorizer()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tips[['sex', 'smoker', 'day', 'time']].to_dict(orient='records')\n",
    "d[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(d, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].transform(d).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(d, tips.tip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Realistic) Sklearn Pipelines\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* `ColumnTransformer` is a new (experimental) Pipeline object \n",
    "* Transforms using multiple transformers, each on different columns.\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_3.png\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.drop(['tip', 'total_bill', 'size'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns and associated transformers\n",
    "num_feat = ['total_bill', 'size']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_feat = ['sex', 'smoker', 'day', 'time']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('intenc', pp.OrdinalEncoder()),\n",
    "    ('onehot', pp.OneHotEncoder())\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(transformers=[('num', num_transformer, num_feat), ('cat', cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(tips.drop('tip', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the fit model\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_4.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a model\n",
    "\n",
    "* Given a fit model on dataset, calculate e.g. the root-mean-square error.\n",
    "* If the error is low, do you think it's a good model?\n",
    "    - It fits the given *data* well, but is it a good model? (Is the sample representative?)\n",
    "    - E.g. will it give good predictions on similar, unknown, data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fundamental Concepts of the quality of a 'fit model'\n",
    "\n",
    "* **Bias**: the expected deviation between the predicted value and true value\n",
    "* **Variance**:\n",
    "    - **Observation Variance**: the variability of the random noise in the process we are trying to model. \n",
    "    - **Estimated Model Variance**: the variability in the predicted value across different datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Quality: Bias and Variance\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* The red bulls-eye: the true behavior of DGP\n",
    "* Each dart: a specific function that models/predicts the DGP\n",
    "* The model parameters $\\theta$ select these functions.\n",
    "* Credit: Scott Fortmann-Roe\n",
    "    \n",
    "<img src=\"imgs/image_5.png\" width=\"100%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a linear model\n",
    "\n",
    "Given a dataset on which to fit the regression coefficients:\n",
    "1. Calculate the RMSE to test for bias.\n",
    "2. To test for variance, bootstrap estimate the regression coefficients:\n",
    "    - sample the data.\n",
    "    - For each sample, calculate the linear predictor.\n",
    "    - For each input feature, calculate the CI for the distribution of predictions.\n",
    "    - Large \"prediction intervals\" imply the model is susceptible to noise (e.g. outliers)\n",
    "    \n",
    "Still, this relies on a \"representative sample\" for generalization to new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x='total_bill', y='tip');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a fit (non-linear) model, there are three possibilities for quality:\n",
    "    - The model doesn't fit the given data well (high bias; underfit)\n",
    "    - Does it reflect the process of interest? (good fit; robust)\n",
    "    - Does it just fit the data (noise and all)? (high variance; overfit)\n",
    "\n",
    "* How can we ascertain the quality on similar, out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a quadratic process, a linear model has high bias.\n",
    "* \"Connecting-the-dots\" will fail to generalize (high variance).\n",
    "\n",
    "![overfit](imgs/under-over-fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: predicting survival on the Titanic with Decision Trees\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Did a given passenger survive the Titanic distaster?\n",
    "* The (simple) tree below has mediocre accuracy\n",
    "\n",
    "<img src=\"imgs/image_6.png\" width=\"50%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducing Bias with more complicated models\n",
    "\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Improve performance by \"growing\" the decision tree model.\n",
    "* Increase the depth of the tree.\n",
    "* Decrease the number of passengers required in leaf nodes.\n",
    "* Effect: \"Learn\" individual passengers?\n",
    "\n",
    "<img src=\"imgs/image_7.png\" width=\"100%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "To assess your model for overfitting to the data, randomly split the data into a \"training set\" and a \"test set\".\n",
    "\n",
    "* The training set is used to fit the model (train the predictor).\n",
    "* The test set is used to test the goodness-of-fit of the fit model.\n",
    "\n",
    "Leaving out a sample for evaluation is *similar* to bootstrap estimating a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The machine learning training pipeline:\n",
    "\n",
    "<img src=\"imgs/train-test.png\" width=\"50%\">\n",
    "\n",
    "Scikit-Learn as functions that help us do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Scikit-Learn for train-test split\n",
    "\n",
    "* Splitting a dataset using `sklearn.model_selection.train_test_split` \n",
    "* Given features `X` and a target array `y`,\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "```\n",
    "randomly splits the features and target into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tips.drop('tip', axis=1)\n",
    "y = tips.tip\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(X_train)/len(X),\n",
    "    len(X_test)/len(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Prediction Pipeline\n",
    "\n",
    "* Train a simple linear regression model on the tips data\n",
    "* Split the data into a training and test set:\n",
    "    - fit the model on the training set\n",
    "    - compute the error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time' ], axis=1)\n",
    "y = tips.tip\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "   ('lin-reg', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "pl.fit(X_test, y_test)\n",
    "print (\"Accuracy: %s\" % pl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
